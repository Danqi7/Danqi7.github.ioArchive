---
layout: post
title:  "[翻译] 软件2.0"
date:   2017-12-12 13:49:07 +0800
categories: jekyll translate
---
> Not original work, just translation of [Software 2.0 by Andrej Karpathy](https://medium.com/@karpathy/software-2-0-a64152b37c35).
> I don't owe anything.

> 非原创，翻译。原作： [Software 2.0](https://medium.com/@karpathy/software-2-0-a64152b37c35) 作者：Andrej Karpathy (现特斯拉 AI 主管)

> Email me if I am violating anything.

我有时会看到人们将神经网络称为“机器学习工具箱中的另一个工具”。他们有一些优点和缺点，他们有时有效，有时却表现不尽人意。有时你还可以用神经网络赢得Kaggle比赛。不幸的是，这种解释完全可以说是丢了西瓜，捡了芝麻。神经网络不仅仅是另一个分类器，它代表了我们如何编写软件的根本转变的开始。他们是软件 2.0。

软件 1.0的 “经典堆栈” 是我们所熟悉的 - 它是用Python，C ++等语言编写的。程序员编写的明确指令组成了软件 1.0。 程序员通过编写每一行代码来识别在程序空间里的某一个可行的程序。

![alt text](https://cdn-images-1.medium.com/max/1600/1*CHcu2L0NmAZwCpQgmS1ByA.jpeg "image1")

相比之下，软件 2.0是用神经网络权重编写的。没有人参与编写这个代码，因为有很多的权重（典型的网络可能有数百万），直接用权重编码是困难的（我试过）。相反，我们对一个理想的程序（例如一个数据集，里面是理想的输入输出）的行为限定了一些约束，并使用我们计算资源在程序空间中搜索满足条件的程序。使用神经网络，我们将搜索限制在程序空间的一个连续的子集，用反向传播和随机梯度下降来进行搜索：这样的搜索过程出人意外地有效。

事实证明，大部分现实世界的问题具有收集数据比明确写入程序要容易得多的性质。未来程序员很大一部分不会维护复杂的软件库，编写错综复杂的程序或分析其运行时间。他们收集，清理，操纵，标记，分析和可视化神经网络使用的数据。

![alt text](https://cdn-images-1.medium.com/max/1600/1*6EB1Xue1wM_QP0IIzXphQA.png "image2")

软件 2.0不会取代软件 1.0（实际上，需要大量的1.0基础设施来训练和推断，进而 “编译” 2.0代码），但是它将接管软件1.0当今负责的越来越多的部分。让我们来看一些正在进行的过渡的例子，以便更具体一些：

**视觉识别** 过去由工程特征组成，在最后（如SVM）的最顶层运用了一些机器学习。从那以后，我们开发了一个机制来发现更强大的图像分析程序（在卷积网络体系结构中），最近我们已经开始寻找[程序构架](https://arxiv.org/abs/1703.01041)。

**语音识别** 过去涉及到大量的预先处理，高斯混合模型和隐马尔可夫模型，但是[今天](https://github.com/syhw/wer_are_we)几乎完全由神经网络组成。

**语音合成** 在历史上已经用各种拼接机制来处理，但是现在最先进的模型是产生原始音频信号输出的大型卷积网络（例如[WaveNet](https://deepmind.com/blog/wavenet-launches-google-assistant/)）。

**机器翻译** 通常是基于短语统计技术的方法，但是神经网络正迅速成为主导。我最喜欢的架构是在[多语言](https://arxiv.org/abs/1611.04558)环境中进行培训的，在这种环境下，单一模型可以从任何源语言翻译成任何目标语言，在[弱监督](https://arxiv.org/abs/1710.11041)（或完全无人监督）的环境下翻译。

**机器人** 一直以来的传统方法是将传感，姿态估计，计划，控制，不确定性建模等问题分解为多个问题，并用算法来解决这些问题。我们目前还不是很清楚，但[加州大学伯克利分校](https://www.bloomberg.com/features/2015-preschool-for-robots/)和[谷歌](https://research.googleblog.com/2016/03/deep-learning-for-robots-learning-from.html)的研究表明，软件 2.0 可能会更好地解决这些问题。

**游戏**。 围棋已经存在了很长一段时间，但是[阿尔法狗 Zero](https://deepmind.com/blog/alphago-zero-learning-scratch/)（一个用卷积网络来看着棋盘的原始状态，决定下一步) 现在已经成为了这个游戏中最强大的玩家。我预计在其他领域会看到非常相似的结果，比如[DOTA 2](https://blog.openai.com/more-on-dota-2/)或[星际争霸](https://deepmind.com/blog/deepmind-and-blizzard-open-starcraft-ii-ai-research-environment/)。

你会发现上面的很多链接都涉及到谷歌完成的工作。这是因为谷歌目前处于将自己大部分代码转移成软件 2.0 的最前沿。 [“一个统一所有制度的模式”](https://arxiv.org/abs/1706.05137)为我们提供了一个初步的概念，即将各个领域的统计强度合并为一个一致理解。

**软件2.0的好处**

为什么我们更喜欢将复杂的程序移植到软件 2.0 中？答案非常简单，因为软件 2.0 表现更出色。除此之外，还有很多方便的理由来选择这个堆栈。让我们来看看软件 2.0的一些好处（试想一个卷积网络）与软件 1.0相比（试想一个生产级的C ++代码库）。软件2.0是：

**计算均匀。** 一个典型的神经网络是由一个只有两个操作的三明治构成的：矩阵乘法和零点阈值（ReLU）。将其与软件1.0 的指令集进行比较，软件1.0指令集显得更为异构和复杂。对于软件2.0来说， 只需为少数核心计算原语（例如矩阵乘法）提供软件1.0实现，我们就可以更容易地保证软件的各种正确性和性能。

**很容易用硅芯片实现。** 作为推论，因为神经网络的指令集相对较小，所以实现这些网络非常接近于硅，例如，用定制的[ASIC](https://www.forbes.com/sites/moorinsights/2017/08/04/will-asic-chips-become-the-next-big-thing-in-ai/#7d6d7c0511d9)，[神经形态的芯片](https://spectrum.ieee.org/semiconductors/design/neuromorphic-chips-are-destined-for-deep-learningor-obscurity)等等。当低能力的智能在我们周围变得普遍时，世界发生改变。例如，小巧便宜的芯片可以附带一个预先训练好的卷积网络，一个语音识别器和一个WaveNet语音合成网络。所有这些都可以集成在一个小的原生生物体中，你可以附加这个芯片到任何东西上。

**常量的运行时间** 典型的神经网络正向传递的每一次迭代都需要完全相同的FLOPS量。基于不同的执行路径，你的代码可能会通过一些庞大的C ++代码库来实现零变化。当然，你可以有动态的计算图，但执行流程通常仍然受到很大的限制。这样我们也几乎可以保证永远不会发现自己的程序处于无意识的无限循环中。

**常量的内存使用。** 与上面相关的是，在任何地方都没有动态分配的内存，所以电脑交换磁盘和内存泄露可能性也很小。

**非常便携。** 与传统的二进制或脚本相比，矩阵乘法的序列在任意的计算配置上运行起来要容易得多。

**非常敏捷。** 如果你有一个C ++代码，并且有人希望你改进代码做两倍的速度（如果需要的话，用减少性能来换取速度），这样的更改调整是非常不容易的。但是，在软件2.0中，我们可以利用我们的网络，删除一半的通道，重新训练。这样我们就可以得到运行速度为两倍，但工作效率更差一些的程序。这简直是魔法。相反，如果你碰巧得到更多的数据/计算，只要增加更多的通道，再次训练就可以立即提高你程序的效率。

**模块可以融合成一个最佳的整体。** 我们的软件经常被分解成通过公开功能，API或端点进行通信的模块。但是，如果两个原本分开训练的 软件2.0 模块相互作用，我们就可以很容易地在整体上反向传播。试想一下，如果你的网页浏览器能够自动地重新设计底层的系统指令堆栈，以实现更高的网页加载效率，那将会是多么惊人。 对于软件2.0来说，这是默认的行为。

**学习起来很容易。** 我喜欢开玩笑说深度学习是浅薄的（并非深入的）。深度学习并不是核物理学：如果你想要用核物理学做一点事情，你得需要核物理的博士学位。深度学习的基础概念需只要基本的线性代数，微积分，Python和CS231n的一些讲座（译者：打广告？）。当然，大量的专业知识和直觉需要时间的积累，所以更精确的说法是，软件2.0堆栈很容易学习和运用，但不是很容易掌握。

**比你厉害比你强。** 最后，也是最重要的一点，神经网络比你和我能产出更好的代码，目前至少在图像/视频，声音/语音和文字的领域上来说。

**软件2.0的局限性**

2.0堆栈也有其自身的一些缺点。优化结束后的大型网络运行良好，性能出色，但很难说清楚为什么它会这么有效。在许多应用领域，我们将会面临一个选择：选择使用我们理解的90％精确模型，或者使用我们不理解的但精确率99％的模型。

2.0堆栈可能会以不直观和[令人尴尬的方式失败](https://motherboard.vice.com/en_us/article/nz7798/weve-already-taught-artificial-intelligence-to-be-racist-sexist)，或者更糟糕的是，他们可能会“悄无声息地失败”，例如，通过在他们的训练数据中默认采用偏见，这些数据很难正确地分析和检查， 特别是当数据的大小在几百万的多数情况下。

最后，我们仍然发现这个堆栈的一些特殊的奇怪属性。例如，[对抗性的例子](https://motherboard.vice.com/en_us/article/nz7798/weve-already-taught-artificial-intelligence-to-be-racist-sexist)和[攻击的存在](https://blog.openai.com/adversarial-example-research/)突出了这个堆栈的非直觉／直观性。

**最后几个想法**

如果将神经网络看作是一个软件堆栈，而不仅仅是一个很好的分类器，很显然，它们具有大量的优势，并且有很大的潜力来改变软件。

从长远来看，软件2.0的未来是光明的，因为越来越多的人渐渐意识到，当我们开发AGI时，肯定会用2.0软件来写。

软件3.0？ 这完全取决于AGI。（译者：AGI指的是强AI)

> 译者的话： 我是如何翻译这篇文章的？ 我 + [NMT](https://github.com/tensorflow/nmt)
